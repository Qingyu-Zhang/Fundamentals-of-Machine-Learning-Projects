{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c33801c-b43b-4a83-a173-25aa46fb6d13",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fundamentals of Machine Learning (CSCI-UA.473)\n",
    "\n",
    "## Lab 3: Margin Classifiers and Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591dce0-ce60-4b0a-94db-2c65f9e82763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Install autograd:\n",
    "#!conda install -c conda-forge autograd\n",
    "\n",
    "import autograd.numpy as numpy\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "\n",
    "# Import and load dataset for this exercise - pip install palmerpenguins\n",
    "from palmerpenguins import load_penguins\n",
    "# This function returns a pandas dataframe by default (use return_X_y to get it in two numpy arrays)\n",
    "penguins = load_penguins().dropna()\n",
    "X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]\n",
    "y = penguins['species']\n",
    "print(X.shape, y.shape)\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e111f23-c96f-41f7-b65e-a2ebcf3129aa",
   "metadata": {},
   "source": [
    "### Split the data into train and test\n",
    "\n",
    "We'll use a 80/20 split for our training/test sets. We will not touch the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17246384-db54-4b3d-b0dc-9c6f94c2fd8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data.  DO NOT TOUCH THE TEST DATA FROM HERE ON!!\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, test_size = 0.2) # 0.2 is 20% test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834efa6b-d72b-4ad0-a702-deeb42a46351",
   "metadata": {},
   "source": [
    "## Part I : Support Vector Machines\n",
    "We will now play around with the support vector machine. We will first compare them to a standard logistic regression model. Then we will see how they work on datasets which are not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc5aed-4555-4e31-ba6a-073e67056a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the packages we'll need.\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9ff43-4f22-4b23-b88b-eba9d5560454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the linear SVM.\n",
    "\n",
    "svm = LinearSVC(C = 1e10, dual = False) # Uses the squared-hinge loss function when fitting the model.\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a579f-c71a-4b2f-9042-e6298a4e6163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now evaluate it on the test points.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Linear SVM validation accuracy = {:0.1f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bade89-5797-4ca6-9f07-476ee1a07655",
   "metadata": {},
   "source": [
    "### Case of non-linearly separable dataset\n",
    "\n",
    "If the data is linearly separable, then a linear SVM should be able to achieve nearly 100% accuracy, as we saw with the penguins dataset. We'll use a synthetic dataset to illustrate when this does not happen and mention some techniques to handle it. This data is drawn from a bi-modal Gaussian mixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c73fce-a1fb-4a65-9e7d-4a21033abb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    N : the number of data points\n",
    "\n",
    "Output:\n",
    "    X, y : the features and targets of shapes (N,2) and (N, )\n",
    "\"\"\"\n",
    "def sample_bimodal_data(N, var1=1, var2=1):\n",
    "    \n",
    "    # The two modes and covariances.\n",
    "    mu1 = np.asarray([2, -1])\n",
    "    mu2 = np.asarray([-2, 1])\n",
    "    \n",
    "    cov1 = var1 * np.identity(2)\n",
    "    cov2 = var2 * np.identity(2)\n",
    "    \n",
    "    N1 = N//2   # Number of points in first class.\n",
    "    N2 = N - N1 # Number of points in second class.\n",
    "    \n",
    "    # Sample the random points.\n",
    "    X1 = np.random.multivariate_normal(mu1, cov1, N1)\n",
    "    X2 = np.random.multivariate_normal(mu2, cov2, N2)\n",
    "    Y1 = np.zeros(N1)\n",
    "    Y2 = np.ones(N2)\n",
    "    \n",
    "    # Combine the data.\n",
    "    X = np.vstack((X1, X2))\n",
    "    Y = np.concatenate((Y1, Y2), axis = None)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c99d6-62b2-4deb-8ae0-6926a67ae988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the sample data.\n",
    "N = 500\n",
    "X,Y = sample_bimodal_data(N, var1=2,var2=1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.scatter(X[:N//2, 0], X[:N//2, 1], label = 'Class 0')\n",
    "plt.scatter(X[N - N//2:, 0], X[N - N//2:, 1], label = 'Class 1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Sample Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405399c8-df9f-4077-ac5d-95ddcb5ec28f",
   "metadata": {},
   "source": [
    "Increasing the factor in front of the covariances or shifting the centers of the two distributions to be closer to each other will cause the data to overlap more, making it harder to classify. Lets try that! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5069e-8cc7-4df7-b356-f50e995311e2",
   "metadata": {},
   "source": [
    "#### Using a slack variable C\n",
    "\n",
    "Since the data is not perfectly linearly separable you'll want to use a slack variable which allows SVM to handle this dataset.  Let's train some models with different values of $C$ and compare them using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b0cf4-4ce9-48d8-b44f-39b7837da845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First get the data and split it into training and testing.\n",
    "# Use a 70/30 split, normally we would want 3 splits (including the validation), but in this example we will use sklearn's cross_val_score function to tune our hyperparameters\n",
    "# This means that we are doing k-fold leave one out cross validation and different subsets of our training set will be used as validation sets.\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = model_selection.train_test_split(X, Y, test_size = 0.20, random_state = 981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68ca7d-f533-4b1d-9eaf-2decc2c2c902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the SVM model to use with a slack variable, remember that C here controls the \"inverse\" regularization strength since by decreasing\n",
    "# C we allow more points to lie beyond the correct margin.\n",
    "svm = LinearSVC(C = 1e10, dual = False)\n",
    "svm.fit(Xs_train, Ys_train)\n",
    "svmpred = svm.predict(Xs_test)\n",
    "acc = metrics.accuracy_score(Ys_test, svmpred)\n",
    "print('SVM accuracy = {:0.1f}%'.format(100*acc))\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "\n",
    "# Select indices with certain class, this is useful while indexing from larger arrays\n",
    "I = Ys_test == 0\n",
    "axs[0].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'Actual class 0')\n",
    "I = Ys_test == 1\n",
    "axs[0].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'Actual class 1')\n",
    "axs[0].legend()\n",
    "I = svmpred == 0\n",
    "axs[1].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'Predicted class 0')\n",
    "I = svmpred == 1\n",
    "axs[1].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'Predicted class 1')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654643ab-f54a-4a76-99eb-74123c27b6ff",
   "metadata": {},
   "source": [
    "**Experiment with various different mu1 values and demonstrate SVM accuracy gets worse as mu1 and mu2 get closer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f347b5-0331-4ca3-819a-84a3989f6b30",
   "metadata": {},
   "source": [
    "Let's train some models with different $C$ and compare them use cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d70b27-d67c-42e5-8a0b-8dd6c910d9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "svm_1 = LinearSVC(C = 10, dual = False)\n",
    "svm_2 = LinearSVC(C = 1, dual = False)\n",
    "svm_3 = LinearSVC(C = 1e-3, dual = False)\n",
    "svm_4 = LinearSVC(C = 1e-7, dual = False)\n",
    "\n",
    "split = model_selection.KFold(5)\n",
    "# Get the CV scores.\n",
    "cv_1 = model_selection.cross_val_score(svm_1, Xs_train, Ys_train, cv = split)\n",
    "cv_2 = model_selection.cross_val_score(svm_2, Xs_train, Ys_train, cv = split)\n",
    "cv_3 = model_selection.cross_val_score(svm_3, Xs_train, Ys_train, cv = split)\n",
    "cv_4 = model_selection.cross_val_score(svm_4, Xs_train, Ys_train, cv = split)\n",
    "\n",
    "# Print the average scores.\n",
    "print('C = 10    CV average score = {:0.1f}%'.format(np.mean(cv_1) * 100))\n",
    "print('C = 1     CV average score = {:0.1f}%'.format(np.mean(cv_2) * 100))\n",
    "print('C = 1e-3  CV average score = {:0.1f}%'.format(np.mean(cv_3) * 100))\n",
    "print('C = 1e-7  CV average score = {:0.1f}%'.format(np.mean(cv_4) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a776be-32f5-41c1-b5b1-2ee41ed1770f",
   "metadata": {},
   "source": [
    "We see that the model performs slightly differently for different values of the slack variable $C$.  \n",
    "\n",
    "$$\n",
    "\\min_{w,b,\\zeta} \\frac{1}{2}w^Tw + C\\sum_{i=1}^n \\zeta_i,\\quad \\text{ such that }\\quad y_i(w^Tx_i + b) \\ge 1 - \\zeta_i,\\quad \\zeta_i \\ge 0\n",
    "$$\n",
    "\n",
    "See the sci-kit [documentation](https://scikit-learn.org/stable/modules/svm.html) for more details.  We can also plot a curve of the validation score for many different $C$ values which can be helpful for determining the optimal hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc69d8e-4bf9-4953-b3bd-b372d3bbdf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the C values we want to look at.\n",
    "C = 1/(2**np.arange(0, 20)) # 1,...,1e-6\n",
    "\n",
    "k = 10 # Kfold CV.\n",
    "cv_scores = np.zeros(len(C))\n",
    "split = model_selection.KFold(k)\n",
    "for i in range(len(C)):\n",
    "    svm = LinearSVC(C = C[i], dual = False)\n",
    "    cv_scores[i] = np.mean(model_selection.cross_val_score(svm, Xs_train, Ys_train, cv = split))\n",
    "\n",
    "plt.figure(2)\n",
    "plt.semilogx(C, cv_scores, 'b-x')\n",
    "plt.xlabel(r'$C$')\n",
    "plt.ylabel(r'Score')\n",
    "plt.title(r'{:d}-Fold CV Score for Linear SVM'.format(k))\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f88753-01bb-4309-a111-bc16d9db4f71",
   "metadata": {},
   "source": [
    "We can use this plot to find the optimal value of the slack variables based on the cross validation score. Now let's see how our 4 models from earlier actually do on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31250a62-27c0-4d5a-a0de-2102ff0d7eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "svm_1 = LinearSVC(C = 10, dual = False)\n",
    "svm_2 = LinearSVC(C = 1, dual = False)\n",
    "svm_3 = LinearSVC(C = 1e-3, dual = False)\n",
    "svm_4 = LinearSVC(C = 1e-7, dual = False)\n",
    "\n",
    "# Fit the models.\n",
    "svm_1.fit(Xs_train, Ys_train)\n",
    "svm_2.fit(Xs_train, Ys_train)\n",
    "svm_3.fit(Xs_train, Ys_train)\n",
    "svm_4.fit(Xs_train, Ys_train)\n",
    "\n",
    "# Make the predictions.\n",
    "pred1 = svm_1.predict(Xs_test)\n",
    "pred2 = svm_2.predict(Xs_test)\n",
    "pred3 = svm_3.predict(Xs_test)\n",
    "pred4 = svm_4.predict(Xs_test)\n",
    "\n",
    "# Evaluate the models.\n",
    "acc1 = metrics.accuracy_score(Ys_test, pred1)\n",
    "acc2 = metrics.accuracy_score(Ys_test, pred2)\n",
    "acc3 = metrics.accuracy_score(Ys_test, pred3)\n",
    "acc4 = metrics.accuracy_score(Ys_test, pred4)\n",
    "\n",
    "print('Linear SVM (C = 10)   accuracy = {:0.1f}%'.format(100*acc1))\n",
    "print('Linear SVM (C = 1)    accuracy = {:0.1f}%'.format(100*acc2))\n",
    "print('Linear SVM (C = 1e-3) accuracy = {:0.1f}%'.format(100*acc3))\n",
    "print('Linear SVM (C = 1e-7) accuracy = {:0.1f}%'.format(100*acc4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68fda1-374c-4949-ad6c-d4854745f468",
   "metadata": {},
   "source": [
    "### Another non-linearly separable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f4921-b8e7-4be3-8711-e4a486616564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    N : the number of data points\n",
    "\n",
    "Output:\n",
    "    X, y : the features and targets of shapes (N,2) and (N, )\n",
    "\"\"\"\n",
    "def gen_data1(N):\n",
    "    N1 = N//2\n",
    "    N2 = N - N1\n",
    "    t = np.linspace(0, 2*np.pi, N1)\n",
    "    \n",
    "    X1 = np.zeros((N1, 2))\n",
    "    X1[:,0] = 4*np.cos(t) + 0.1*np.random.randn(N1)\n",
    "    X1[:,1] = 4*np.sin(t) + 0.1*np.random.randn(N1)\n",
    "    y1 = np.zeros(N1)\n",
    "    \n",
    "    X2 = np.random.randn(2*N2)\n",
    "    X2 = X2.reshape((N2, 2))\n",
    "    y2 = np.ones(N2)\n",
    "\n",
    "    # Combine the data.\n",
    "    X = np.vstack((X1, X2))\n",
    "    y = np.concatenate((y1, y2), axis = None) # axis = None means that arrays flattened before use\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb351fc-ee45-4387-b87b-f93ddbd7ac2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the data.\n",
    "N = 1000\n",
    "Xs, Ys = gen_data1(N)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.scatter(Xs[:N//2, 0], Xs[:N//2, 1], label = 'Class 0')\n",
    "plt.scatter(Xs[N - N//2:, 0], Xs[N - N//2:, 1], label = 'Class 1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title('Sample Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ef131-92dc-4040-a837-a8e4bf3feb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "# Use a 70/30 split, we are not performing any validation steps here\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = model_selection.train_test_split(Xs, Ys, test_size = 0.3, random_state = 981)\n",
    "svm = LinearSVC(C = 1e10, dual = False)\n",
    "svm.fit(Xs_train, Ys_train)\n",
    "svmpred = svm.predict(Xs_test)\n",
    "acc = metrics.accuracy_score(Ys_test, svmpred)\n",
    "print('SVM accuracy = {:0.1f}%'.format(100*acc))\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "\n",
    "# Select indices with certain class, this is useful while indexing from larger arrays\n",
    "I = Ys_test == 0\n",
    "axs[0].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'Actual class 0')\n",
    "I = Ys_test == 1\n",
    "axs[0].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'Actual class 1')\n",
    "axs[0].legend()\n",
    "I = svmpred == 0\n",
    "axs[1].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'predicted class 0')\n",
    "I = svmpred == 1\n",
    "axs[1].scatter(Xs_test[I, 0], Xs_test[I, 1], label = 'prediced class 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f013f-92b3-44c2-bddc-d6d225ba9aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return (rho, phi)\n",
    "\n",
    "pX = np.vstack(cart2pol(Xs[:, 0], Xs[:, 1])).T\n",
    "print(pX.shape)\n",
    "plt.figure(4)\n",
    "plt.scatter(pX[:N//2, 0], pX[:N//2, 1], label = 'Class 0')\n",
    "plt.scatter(pX[N - N//2:, 0], pX[N - N//2:, 1], label = 'Class 1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$p_1$ (radius)')\n",
    "plt.ylabel(r'$p_2$ (angle)')\n",
    "plt.title('Sample Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1e7ea-1318-4799-a392-2b82f44b4869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the different SVM models to use\n",
    "# Use a 70/30 split\n",
    "Xs_train, Xs_val, Ys_train, Ys_val = model_selection.train_test_split(pX, Ys, test_size = 0.3, random_state = 981)\n",
    "svm = LinearSVC(C = 1e+10, dual = False)\n",
    "svm.fit(Xs_train, Ys_train)\n",
    "svmpred = svm.predict(Xs_val)\n",
    "acc = metrics.accuracy_score(Ys_val, svmpred)\n",
    "print('SVM accuracy = {:0.1f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0277a58-9252-466a-a94a-a17d89079d50",
   "metadata": {},
   "source": [
    "## Part II : Trees - Decisions Trees, Random Forests and Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5e6fc-aed4-4bdd-926b-abfd86fdecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Import and load dataset for this exercise - pip install palmerpenguins\n",
    "from palmerpenguins import load_penguins\n",
    "# This function returns a pandas dataframe by default (use return_X_y to get it in two numpy arrays)\n",
    "penguins = load_penguins().dropna()\n",
    "X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]\n",
    "y = penguins['species']\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe370a1-9558-48ff-b74f-2da92408831b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a simple decision tree classifier with splitting using gini criterion\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# Fit our penguins data on this, rememeber we had already split this dataset at the begining and should use the same splits across methods\n",
    "# if we want to compare the performance.\n",
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f6348-1c20-449c-85fb-20167e2340bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict using the fitted decision tree\n",
    "preds = clf.predict(X_test)\n",
    "print(np.sum(preds == y_test)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72f8d46-6ac7-4394-b34a-eef3754f4a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a simple decision tree classifier with splitting using entropy criterion\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Fit our penguins data on this, rememeber we had already split this dataset at the begining and should use the same splits across methods\n",
    "# if we want to compare the performance.\n",
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790efee7-6a0e-44d1-ab92-9992ec6d5a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict using the fitted decision tree\n",
    "preds = clf.predict(X_test)\n",
    "print(np.sum(preds == y_test)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16db2b-30be-41ae-a533-2bdfd7c71d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was your vanilla Decision trees, now lets look at Bagging.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Remember, Bagging is just using an ensemble of decision trees to add more variance to your model.\n",
    "# So we simply wrap our original DecisionTreeClassifier with a BaggingClassifier module.\n",
    "clf = BaggingClassifier(estimator=tree.DecisionTreeClassifier(criterion='gini'),\n",
    "                       n_estimators=100, max_samples=1.0, max_features=0.5,bootstrap=True)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# What would setting n_estimators as 1 mean?\n",
    "# Changing the value for n_estimators changes our accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbad9a4-2163-4324-9444-4ab0da50811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(np.sum(preds == y_test)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1319caa-d4f4-467d-9582-891aeef9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Now we try RandomForests on the same data. Again, RandomForests is just a method to ensemble your base models\n",
    "# and will be used in the same way bagging was. The difference is in the number of features being selected to make a node split\n",
    "clf = RandomForestClassifier(n_estimators=100, max_samples=0.1, max_features=0.5,bootstrap=True, criterion='gini')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c58259-47e3-44d0-9f4d-d5467d51500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(np.sum(preds == y_test)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c35028-8c39-4025-8333-950bb9fd32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we implement gradient boosting, in particular the Adaboost algorithm.\n",
    "# Remember, gradient boosting algorithms involve iteratively improving the decision trees\n",
    "# and hence involve a learning rate similar to logistic regressions.\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778166e-5cc9-4673-a673-806b278fbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(\n",
    "    tree.DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=100, learning_rate=1\n",
    ")\n",
    "bdt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9e091-7130-492e-9dca-57a741c3c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bdt.predict(X_test)\n",
    "print(np.sum(preds == y_test)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73932695-7949-47fb-af7d-2f9dd4e8c8e0",
   "metadata": {},
   "source": [
    "### Palmer penguins is a rather simple toy dataset, lets try the decision tree on a more meaningful one - images of handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a50806-eade-4221-9417-f4faa9842dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import graphviz # Use pip install graphviz\n",
    "\n",
    "# We use the digits dataset provided by sklearn, this is similar to MNIST but much coarser (8x8) and \n",
    "# thus a lot lighter than MNIST (28x28)\n",
    "dataset = load_digits()\n",
    "X, Y = dataset.data, dataset.target\n",
    "idxs = np.arange(0, len(X))\n",
    "np.random.shuffle(idxs)\n",
    "train_idxs,test_idxs = idxs[:1500], idxs[1500:]\n",
    "train_X, train_Y = X[train_idxs], Y[train_idxs]\n",
    "test_X, test_Y = X[test_idxs], Y[test_idxs]\n",
    "plt.gray()\n",
    "plt.matshow(dataset.images[101])\n",
    "print(dataset.target[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc51ec4-c6bb-426f-9e59-c54fea299086",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "labels_str = [str(item) for item in dataset.target_names.tolist()]\n",
    "dot_data = tree.export_graphviz(clf, out_file='graph.dot', \n",
    "                      feature_names=dataset.feature_names,  \n",
    "                      class_names=labels_str,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "!dot -Tpng graph.dot -o graph.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4452a8b-a45f-4d79-973e-34449df2a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the fitted decision tree\n",
    "preds = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8385d-1557-43ff-9b54-8442cd41cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(preds == test_Y)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b990f-198b-4493-9315-ec829f09d218",
   "metadata": {},
   "source": [
    "### Bagging Classifiers\n",
    "The BaggingClassifier class in sklearn takes as argument a base estimator (we are use DecisionTrees), and 'n_estimators' - the number of such base estimators. This is a crucial hyperparameter that controls the strength of ensembling effect. Additionally, it takes in 'max_samples' which denotes the number of samples subsampled with replacement (if bootstrap is True) for each of the base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815b53d-1a45-41e0-9a64-2cd241771f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using Bagging.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Remember, Bagging is just using an ensemble of decision trees to add more variance to your model.\n",
    "# So we simply wrap our original DecisionTreeClassifier with a BaggingClassifier module.\n",
    "clf = BaggingClassifier(estimator=tree.DecisionTreeClassifier(criterion='gini'),\n",
    "                       n_estimators=100, max_samples=1.0, bootstrap=True)\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "# What would setting n_estimators as 1 mean?\n",
    "# Changing the value for n_estimators changes our accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272ba32-fa7e-494b-a1b3-217215cd08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b7651-baf8-491e-bbe1-13f1cd3acac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(preds == test_Y)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acae38-bb1e-4b53-8118-aef0c5befe4c",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "Similar to the BaggingClassifier, the RandomForestClassifier uses the hyperparameter 'n_estimators' for the number of base estimators, however for Random Forests the base estimator is constrained to be a decision tree. It uses two more crucial hyperparameters, 'max_samples' denoting the number of samples randomly drawn with replacement (again if bootstrap is True) for each tree and 'max_features' which denotes the number of features to be drawn randomly when performing each node split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78156d59-a21b-40d9-af6c-41e204b1e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Now we try RandomForests on the same data. Again, RandomForests is just a method to ensemble your base models\n",
    "# and will be used in the same way bagging was\n",
    "clf = RandomForestClassifier(n_estimators=100, max_samples=0.5, max_features=0.5,bootstrap=True, criterion='gini')\n",
    "clf.fit(train_X, train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad191c6-e7d3-459c-bf32-17a193ee2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d84cf3-bf3c-4b6f-b1c7-20b16a2ac76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(preds == test_Y)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705389b-a6b6-45ac-b07d-9e00063de766",
   "metadata": {},
   "source": [
    "### Boosting - Adaboost\n",
    "An AdaBoost classifier is a estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases. There are three hyperparameters to note, the base_estimator used (DecisionTree below), the number of estimators (n_estimators) and 'learning_rate' which controls the weight applied to each boosting iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52c284-e2d2-4e7d-aba6-488376291149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(\n",
    "    tree.DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=2000, learning_rate=1\n",
    ")\n",
    "bdt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092d95c-5515-4c10-a6f6-00ea3f228e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bdt.predict(X_test)\n",
    "print(np.sum(preds == y_test)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd0b81-43ee-410f-acf0-4b984b04dd22",
   "metadata": {},
   "source": [
    "### Now we take a closer look at how the hyperparameters of each tree algorithm affects its decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d0b58-4d3d-4290-8fad-9cda4b0946f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, gradient boosting algorithms involve iteratively improving the decision trees\n",
    "# and hence involve a learning rate similar to logistic regressions.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "# Construct dataset\n",
    "X1, y1 = make_gaussian_quantiles(\n",
    "    cov=2.0, n_samples=200, n_features=2, n_classes=2, random_state=1\n",
    ")\n",
    "X2, y2 = make_gaussian_quantiles(\n",
    "    mean=(3, 3), cov=1.5, n_samples=300, n_features=2, n_classes=2, random_state=1\n",
    ")\n",
    "X = np.concatenate((X1, X2))\n",
    "y = np.concatenate((y1, -y2+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae63f81-d1de-4856-b53f-76e04672d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training points\n",
    "plot_colors = \"br\"\n",
    "plot_step = 0.02\n",
    "class_names = \"AB\"\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=c,\n",
    "        cmap=plt.cm.Paired,\n",
    "        s=20,\n",
    "        edgecolor=\"k\",\n",
    "        label=\"Class %s\" % n,\n",
    "    )\n",
    "    plt.xlabel(r'$X_0$')\n",
    "    plt.ylabel(r'$X_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8dcb50-4d78-4574-a780-be64a1a20aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(\n",
    "    tree.DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=100, learning_rate=1\n",
    ")\n",
    "bdt.fit(X, y)\n",
    "\n",
    "# Create and fit a Random forest \n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_samples=0.5, max_features=0.5,bootstrap=True, criterion='gini')\n",
    "clf_rf = clf_rf.fit(X, y)\n",
    "\n",
    "clf_bg = BaggingClassifier(estimator=tree.DecisionTreeClassifier(criterion='gini'),\n",
    "                       n_estimators=100, max_samples=1.0, bootstrap=True)\n",
    "clf_bg = clf_bg.fit(X, y)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdef8fa-baf0-4d85-b393-ba236242e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "classifiers = [clf, clf_bg, clf_rf, bdt]\n",
    "names = [\"Vanilla Decision Tree\", \"Bagging\", \"Random Forest\", \"Adaboost\"]\n",
    "for i, clf in enumerate(classifiers):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(names[i])\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step)\n",
    "    )\n",
    "\n",
    "    # Make predictions using fitted tree\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Plot the training points\n",
    "    for j, n, c in zip(range(2), class_names, plot_colors):\n",
    "        idx = np.where(y == j)\n",
    "        plt.scatter(\n",
    "            X[idx, 0],\n",
    "            X[idx, 1],\n",
    "            c=c,\n",
    "            cmap=plt.cm.Paired,\n",
    "            s=20,\n",
    "            edgecolor=\"k\",\n",
    "            label=\"Class %s\" % n,\n",
    "        )\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf1f18-79b3-490c-a906-1d531d5f1262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

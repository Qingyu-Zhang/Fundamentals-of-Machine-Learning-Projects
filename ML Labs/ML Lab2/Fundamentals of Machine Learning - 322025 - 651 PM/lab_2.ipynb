{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Machine Learning (CSCI-UA.473)\n",
    "\n",
    "## Lab 2: Regularized Regression, Logistic Regression and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import some packages we'll need.\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression and Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters:\n",
    "noiseMagnitude = 10 # how much random noise is there?\n",
    "numData = 8 # how many measurements (samples) of the signal?\n",
    "numPoints = 1001 \n",
    "leftRange = -5 \n",
    "rightRange = 5\n",
    "x = np.linspace(leftRange,rightRange,numPoints) # determine the location \n",
    "# of evenly spaced points from -5 to 5 to use as an x-base\n",
    "\n",
    "# Determine the functional relationship between x and y in reality (ground truth):\n",
    "sig = 2 # user determines whether the signal is quadratic (1) or cubic (2)\n",
    "if sig == 1:\n",
    "    y1 = x**2 # quadratic function\n",
    "elif sig == 2:\n",
    "    y1 = x**3 # cubic function\n",
    "    \n",
    "# Compute signal plus noise:\n",
    "y = y1 + noiseMagnitude * np.random.normal(0,1,numPoints) # signal + noise\n",
    "\n",
    "# Plot data:\n",
    "plt.figure(1)\n",
    "plt.plot(x,y1,color='blue',linewidth=5)\n",
    "plt.xlabel('X') \n",
    "plt.ylabel('Y')  \n",
    "plt.title('Ground Truth')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(x,y,color='blue',linewidth=1)\n",
    "plt.xlabel('X') \n",
    "plt.ylabel('Y')  \n",
    "plt.title('Signal plus noise')\n",
    "\n",
    "#Ground truth with noise in one plot\n",
    "plt.figure(3)\n",
    "plt.plot(x,y,color='blue',linewidth=1)\n",
    "plt.plot(x,y1,color='black',linewidth=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Determine the location of the sampling (measuring) points \n",
    "\n",
    "# Randomly draw points to sample:\n",
    "samplingIndices = np.random.randint(1,numPoints,numData) # random points, from anywhere on the signal\n",
    "\n",
    "# Plot data as a subsample of the noisy signal:\n",
    "plt.plot(x,y,color='blue',linewidth=1)\n",
    "plt.plot(x,y1,color='black',linewidth=5)\n",
    "plt.plot(x[samplingIndices],y[samplingIndices],'o',markersize=4,color='red')\n",
    "plt.xlim(-5,5) # keep it on the same x-range as before\n",
    "\n",
    "# Note: Parabola doesn't fit perfectly because there is noise (measurement error). We are\n",
    "# overfitting to noise. The more noise, the worse this effect is\n",
    "# In real life, all measurements are contaminated with noise, so overfitting\n",
    "# to noise is always a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% (Over)fitting successive polynomials and calculating RMSE at each point\n",
    "\n",
    "rmse = np.array([]) # capture RMSE for each polynomial degree\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for ii in range(numData): # loop through each sampling point\n",
    "    ax = fig.add_subplot(2,4,ii+1)\n",
    "    numDegrees = ii+1 # degree of polynomial to fit to our 8 data points\n",
    "    p = np.polyfit(x[samplingIndices],y[samplingIndices],numDegrees) # returns a vector of coefficients p that minimizes the squared error\n",
    "    yHat = np.polyval(p,x) # evaluate the polynomial at specific values\n",
    "    ax.plot(x,yHat,color='blue',linewidth=1)\n",
    "    ax.plot(x[samplingIndices],y[samplingIndices],'ro',markersize=3)\n",
    "    error = np.sqrt(np.mean((y[samplingIndices] - yHat[samplingIndices])**2))\n",
    "    ax.set_title('Degrees: {}'.format(numDegrees) + ', RMSE = {:.3f}'.format(error))\n",
    "    rmse = np.append(rmse,error) # keep track of RMSE - we will use this later\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y (Signal + Noise)')\n",
    "    \n",
    "fig.suptitle('Fits for different degrees of polynomials')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Plotting RMSE of the training set as function of polynomial degree\n",
    "plt.plot(np.linspace(1,numData,numData),rmse)\n",
    "plt.xlabel('Degree of polynomial')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#%% Leave-one-out procedure to cross-validate the number of terms in the\n",
    "# model. Note: We randomly pick one of the test points to use to calculate\n",
    "# the RMSE with. We use the other data points to fit the model\n",
    "# This method is called \"leave one out\" and is very computationally\n",
    "# expensive, as one has to fit the model n-1 times\n",
    "\n",
    "\n",
    "# Initialize parameters:\n",
    "numRepeats = 50 # Number of samples - how often are we doing this?\n",
    "rmse = np.zeros([numRepeats,numData-1]) # Reinitialize RMSE (100x7)\n",
    "# For each polynomial degree, 100x we are going to randomly pick one of\n",
    "# the points from the set of 8 and compute the RMSE\n",
    "# We are then going to fit the model from the remaining (7) points\n",
    "# This is why we only go up to the 7th degree polynomial\n",
    "\n",
    "# Compute RMSE on test set:\n",
    "for ii in range(numRepeats): # Loop from 0 to 99\n",
    "    testIndex = np.random.randint(0,numData,1) # Randomize test index - pick randint from 0 to 7\n",
    "    testSet = samplingIndices[testIndex] # Find the test set (= 1 random data point from our 8)\n",
    "    trainingSet = np.copy([samplingIndices]) # Make copy of sampling indices\n",
    "    trainingSet = np.delete(trainingSet,testIndex) # Delete the test subset\n",
    "    for jj in range(numData-1): # Loop from 0 to 6 - for each poly degree\n",
    "        numDegrees = jj+1 # degrees are from 1 to 7, so add 1 to jj each time\n",
    "        p = np.polyfit(x[trainingSet],y[trainingSet],numDegrees) # compute coefficients\n",
    "        yHat = np.polyval(p,x)  # then evaluate\n",
    "        # Calculate RMSE with the test set (just the single point we randomly chose above):\n",
    "        rmse[ii,jj] = np.sqrt(np.mean((y[testSet] - yHat[testSet])**2)) # store this in rmse container\n",
    "\n",
    "# Plot data:\n",
    "plt.plot(np.linspace(1,numData-1,7),np.mean(rmse,axis=0))\n",
    "plt.title('Real RMSE as a function of degree of polynomial')\n",
    "plt.xlabel('Degree of polynomial')\n",
    "plt.ylabel('RMSE measured only at points left out from building model')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The solution? Where RMSE is minimal\n",
    "solution = np.amin(np.mean(rmse,axis=0)) # value\n",
    "index = np.argmin(np.mean(rmse,axis=0)) # index\n",
    "print('The RMSE is minimal at polynomial of degree: {}'.format(index+1)) \n",
    "\n",
    "# Note - the console will give you warnings that the polyfit is poorly conditioned sometimes. \n",
    "# That's another dead giveaway that you are overfitting. Too many parameters, not enough data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another solution is to use regularization, where the idea is to penalize large coefficients which lead to noisy curves. There are two popular ways to perform regularization, Lasso and Ridge, which we discuss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "x = np.genfromtxt('mRegDataX.csv',delimiter=',') # satM satV hoursS gpa appreciation fearM fearT\n",
    "y = np.genfromtxt('mRegDataY.csv',delimiter=',') # outcome: class score\n",
    "\n",
    "x_norm = (x - np.mean(x, axis=0))/np.std(x, axis=0)\n",
    "y_norm = (y - np.mean(y, axis=0))/np.std(y, axis=0)\n",
    "\n",
    "# Doing the full model and calculating the yhats:\n",
    "model = LinearRegression().fit(x_norm,y_norm)\n",
    "b0, b1 = model.intercept_, model.coef_\n",
    "y_hat = np.dot(b1,x_norm.transpose()) + b0\n",
    "\n",
    "# Scatter plot between predicted and actual score of full model:\n",
    "r = np.corrcoef(y_hat,y_norm)\n",
    "plt.plot(y_hat,y_norm,'o',markersize=5)\n",
    "plt.xlabel('Predicted grade score')\n",
    "plt.ylabel('Actual grade score')\n",
    "plt.title('R: {:.3f}'.format(r[0,1])) \n",
    "\n",
    "# 4. Splitting the dataset for cross-validation:\n",
    "x1 = np.copy(x_norm[0:100,:])\n",
    "y1 = np.copy(y_norm[0:100])\n",
    "model = LinearRegression().fit(x1,y1)\n",
    "b0_1, b1_1 = model.intercept_, model.coef_\n",
    "\n",
    "x2 = np.copy(x_norm[100:,:])\n",
    "y2 = np.copy(y_norm[100:])\n",
    "model = LinearRegression().fit(x2,y2)\n",
    "b0_2, b1_2 = model.intercept_, model.coef_\n",
    "\n",
    "# 5. Cross-validation. Using the betas from one dataset, but\n",
    "# measuring the error with the other dataset\n",
    "y_hat1 = np.dot(b1_2,x1.transpose()) + b0_2\n",
    "y_hat2 = np.dot(b1_1,x2.transpose()) + b0_1\n",
    "rmse1 = np.sqrt(np.mean((y_hat1 - y1)**2))\n",
    "rmse2 = np.sqrt(np.mean((y_hat2 - y2)**2))\n",
    "print(rmse1, rmse2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Doing the full model and calculating the yhats:\n",
    "model = Ridge(alpha=20).fit(x_norm,y_norm)\n",
    "b0, b1 = model.intercept_, model.coef_\n",
    "y_hat = np.dot(b1,x_norm.transpose()) + b0\n",
    "\n",
    "# 3. Scatter plot between predicted and actual score of full model:\n",
    "r = np.corrcoef(y_hat,y_norm)\n",
    "plt.plot(y_hat,y_norm,'o',markersize=5)\n",
    "plt.xlabel('Predicted grade score')\n",
    "plt.ylabel('Actual grade score')\n",
    "plt.title('R: {:.3f}'.format(r[0,1])) \n",
    "\n",
    "# 4. Splitting the dataset for cross-validation:\n",
    "x1 = np.copy(x_norm[0:100,:])\n",
    "y1 = np.copy(y_norm[0:100])\n",
    "model = Ridge(alpha=20).fit(x1,y1)\n",
    "b0_1, b1_1 = model.intercept_, model.coef_\n",
    "\n",
    "x2 = np.copy(x_norm[100:,:])\n",
    "y2 = np.copy(y_norm[100:])\n",
    "model = Ridge(alpha=20).fit(x2,y2)\n",
    "b0_2, b1_2 = model.intercept_, model.coef_\n",
    "\n",
    "# 5. Cross-validation. Using the betas from one dataset, but\n",
    "# measuring the error with the other dataset\n",
    "y_hat1 = np.dot(b1_2,x1.transpose()) + b0_2\n",
    "y_hat2 = np.dot(b1_1,x2.transpose()) + b0_1\n",
    "rmse1 = np.sqrt(np.mean((y_hat1 - y1)**2))\n",
    "rmse2 = np.sqrt(np.mean((y_hat2 - y2)**2))\n",
    "print(rmse1, rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Doing the full model and calculating the yhats:\n",
    "model = Lasso(alpha=0.1).fit(x_norm,y_norm)\n",
    "b0, b1 = model.intercept_, model.coef_\n",
    "y_hat = np.dot(b1,x_norm.transpose()) + b0\n",
    "\n",
    "# 3. Scatter plot between predicted and actual score of full model:\n",
    "r = np.corrcoef(y_hat,y_norm)\n",
    "plt.plot(y_hat,y_norm,'o',markersize=5)\n",
    "plt.xlabel('Predicted grade score')\n",
    "plt.ylabel('Actual grade score')\n",
    "plt.title('R: {:.3f}'.format(r[0,1])) \n",
    "\n",
    "# 4. Splitting the dataset for cross-validation:\n",
    "x1 = np.copy(x_norm[0:150,:])\n",
    "y1 = np.copy(y_norm[0:150])\n",
    "model = Lasso(alpha=0.1).fit(x1,y1)\n",
    "b0_1, b1_1 = model.intercept_, model.coef_\n",
    "\n",
    "x2 = np.copy(x_norm[150:,:])\n",
    "y2 = np.copy(y_norm[150:])\n",
    "model = Lasso(alpha=0.1).fit(x2,y2)\n",
    "b0_2, b1_2 = model.intercept_, model.coef_\n",
    "\n",
    "# 5. Cross-validation. Using the betas from one dataset, but\n",
    "# measuring the error with the other dataset\n",
    "y_hat1 = np.dot(b1_2,x1.transpose()) + b0_2\n",
    "y_hat2 = np.dot(b1_1,x2.transpose()) + b0_1\n",
    "rmse1 = np.sqrt(np.mean((y_hat1 - y1)**2))\n",
    "rmse2 = np.sqrt(np.mean((y_hat2 - y2)**2))\n",
    "print(rmse1, rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets measure the spread of $\\beta_{OLS}$ by fitting different random subsets of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nReps = 1000\n",
    "betasOLS = np.empty([x.shape[1],nReps])*np.NaN\n",
    "nSample = 100 # Sub-Sampling points\n",
    "nPop = x.shape[0]  # The full population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(nReps): \n",
    "    # Sample nSample number of indexes from our data randomly\n",
    "    sampleIndices = np.random.randint(0,nPop-1,nSample) \n",
    "    trainSamples = x[sampleIndices,:]\n",
    "    # House price, our \"label\" is the fourth feature\n",
    "    labels = trainSamples[:,4]\n",
    "    # Use remaining features for training\n",
    "    features = np.delete(trainSamples, 4, 1)\n",
    "    # The data is varying in scale and variance, subtracting the mean and dividing by the standard deviation is \n",
    "    # a common technique use to \"normalize\" the data\n",
    "    features_norm = (features - np.mean(features, axis=0))/np.std(features, axis=0)\n",
    "    labels_norm = (labels - np.mean(labels, axis=0))/np.std(labels, axis=0)\n",
    "    # Run OLS and store betas:\n",
    "    ols = LinearRegression().fit(features_norm,labels_norm)\n",
    "    betasOLS[:,ii] = np.concatenate((np.array([ols.intercept_]), ols.coef_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBins = 31\n",
    "plt.xlabel(r'$\\beta_{OLS}$')\n",
    "plt.ylabel('Count')\n",
    "plt.title(r'Distribution of $\\beta_{OLS}$')\n",
    "plt.hist(betasOLS[5,:],nBins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets apply our first form of regularized regression - Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pick a value for lambda randomly\n",
    "lambd = 200\n",
    "betasRidge = np.empty([x.shape[1],nReps])*np.NaN\n",
    "for ii in range(nReps):\n",
    "    # We repreat our training process, this time using the Ridge model instead of the vanilla LinearRegression\n",
    "    sampleIndices = np.random.randint(0,nPop-1,nSample) \n",
    "    trainSamples = x[sampleIndices,:]\n",
    "    labels = trainSamples[:,4]\n",
    "    features = np.delete(trainSamples, 4, 1)\n",
    "    features_norm = (features - np.mean(features, axis=0))/np.std(features, axis=0)\n",
    "    labels_norm = (labels - np.mean(labels, axis=0))/np.std(labels, axis=0)\n",
    "    # Run Ridge and store betas:\n",
    "    ridge = Ridge(alpha=lambd).fit(features_norm,labels_norm)\n",
    "    betasRidge[:,ii] = np.concatenate((np.array([ridge.intercept_]), ridge.coef_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBins = 31\n",
    "plt.xlabel(r'$\\beta_{Ridge}$')\n",
    "plt.ylabel('Count')\n",
    "plt.title(r'Distribution of $\\beta_{Ridge}$')\n",
    "plt.hist(betasRidge[5,:],nBins);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe? What happens when you change the value of $\\lambda$ ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets also look at what happens when we use Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pick a value for lambda randomly\n",
    "lambd = 0.1\n",
    "betasLasso = np.empty([x.shape[1],nReps])*np.NaN\n",
    "for ii in range(nReps):\n",
    "    # We repreat our training process, this time using the Ridge model instead of the vanilla LinearRegression\n",
    "    sampleIndices = np.random.randint(0,nPop-1,nSample) \n",
    "    trainSamples = x[sampleIndices,:]\n",
    "    labels = trainSamples[:,4]\n",
    "    features = np.delete(trainSamples, 4, 1)\n",
    "    features_norm = (features - np.mean(features, axis=0))/np.std(features, axis=0)\n",
    "    labels_norm = (labels - np.mean(labels, axis=0))/np.std(labels, axis=0)\n",
    "    # Run Ridge and store betas:\n",
    "    lasso = Lasso(alpha=lambd).fit(features_norm,labels_norm)\n",
    "    betasLasso[:,ii] = np.concatenate((np.array([lasso.intercept_]), lasso.coef_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBins = 31\n",
    "plt.xlabel(r'$\\beta_{Lasso}$')\n",
    "plt.ylabel('Count')\n",
    "plt.title(r'Distribution of $\\beta_{Lasso}$')\n",
    "plt.hist(betasLasso[5,:],nBins);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at how the spread of $\\beta$ values from different regression algorithms compare to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 100\n",
    "betasOLS = np.empty([x.shape[1]+1,nReps])*np.NaN\n",
    "betasRidge = np.empty([x.shape[1]+1,nReps])*np.NaN\n",
    "for ii in range(nReps):\n",
    "    sampleIndices = np.random.randint(0,nPop-1,nSample) \n",
    "    trainSamples = x[sampleIndices,:]\n",
    "    labels = y[sampleIndices]\n",
    "    x_norm = (trainSamples - np.mean(trainSamples, axis=0))/np.std(trainSamples, axis=0)\n",
    "    y_norm = (labels - np.mean(labels, axis=0))/np.std(labels, axis=0)\n",
    "    # Run OLS and store betas:\n",
    "    ols = LinearRegression().fit(x_norm,y_norm)\n",
    "    betasOLS[:,ii] = np.concatenate((np.array([ols.intercept_]), ols.coef_),axis=0)\n",
    "    # Run Ridge and store betas:\n",
    "    ridge = Ridge(alpha=lambd).fit(x_norm,y_norm)\n",
    "    betasRidge[:,ii] = np.concatenate((np.array([ridge.intercept_]), ridge.coef_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a scatter plot for values of betas before and after regularization \n",
    "plt.scatter(betasOLS, betasRidge)\n",
    "plt.xlabel(r'$\\beta_{OLS}$')\n",
    "plt.ylabel(r'$\\beta_{Ridge}$')\n",
    "plt.title(r'Spread of $\\beta_{OLS}$ and $\\beta_{Ridge}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 0.2\n",
    "betasOLS = np.empty([x.shape[1]+1,nReps])*np.NaN\n",
    "betasLasso = np.empty([x.shape[1]+1,nReps])*np.NaN\n",
    "for ii in range(nReps):\n",
    "    sampleIndices = np.random.randint(0,nPop-1,nSample) \n",
    "    trainSamples = x[sampleIndices,:]\n",
    "    labels = y[sampleIndices]\n",
    "    x_norm = (trainSamples - np.mean(trainSamples, axis=0))/np.std(trainSamples, axis=0)\n",
    "    y_norm = (labels - np.mean(labels, axis=0))/np.std(labels, axis=0)\n",
    "    # Run OLS and store betas:\n",
    "    ols = LinearRegression().fit(x_norm,y_norm)\n",
    "    betasOLS[:,ii] = np.concatenate((np.array([ols.intercept_]), ols.coef_),axis=0)\n",
    "    # Run Ridge and store betas:\n",
    "    lasso = Lasso(alpha=lambd).fit(x_norm,y_norm)\n",
    "    betasLasso[:,ii] = np.concatenate((np.array([lasso.intercept_]), lasso.coef_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a scatter plot for values of betas before and after regularization \n",
    "plt.scatter(betasOLS, betasLasso)\n",
    "plt.xlabel(r'$\\beta_{OLS}$')\n",
    "plt.ylabel(r'$\\beta_{Lasso}$')\n",
    "plt.title(r'Spread of $\\beta_{OLS}$ and $\\beta_{Lasso}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now how to pick the right values for $\\lambda$?\n",
    "$\\lambda$ in both Ridge and Lasso Regressions is what we call a \"hyperparameter\". <br/>\n",
    "Why is $\\lambda$ not just a parameter? In other words, why can we not just learn $\\lambda$ like we are learning our $\\beta$'s ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ridge regression to find optimal lambda: a scikit-learn implementation\n",
    "# Load libraries:\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Init parameters:\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x_norm, y_norm.reshape(-1,1), test_size=0.2, random_state=0)\n",
    "lambdas = np.linspace(0.001,200,201)\n",
    "cont = np.empty([len(lambdas),2])*np.NaN # [lambda error]\n",
    "\n",
    "for ii in range(len(lambdas)):\n",
    "    ridgeModel = Ridge(alpha=lambdas[ii]).fit(xTrain, yTrain)\n",
    "    cont[ii,0] = lambdas[ii]\n",
    "    error = mean_squared_error(yTest,ridgeModel.predict(xTest),squared=False)\n",
    "    cont[ii,1] = error\n",
    "\n",
    "plt.plot(cont[:,0],cont[:,1])\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Ridge regression')\n",
    "plt.show()\n",
    "print('Optimal lambda:',lambdas[np.argmax(cont[:,1]==np.min(cont[:,1]))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 5. Now do the same thing--but with lasso regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Just to ignore warnings that might be thrown due to artifically formed data.\n",
    "\n",
    "# Load libraries:\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Init parameters:\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x_norm, y_norm.reshape(-1,1), test_size=0.2, random_state=1)\n",
    "lambdas = np.logspace(-2,0,201)\n",
    "cont = np.empty([len(lambdas),2])*np.NaN # [lambda error]\n",
    "\n",
    "for ii in range(len(lambdas)):\n",
    "    ridgeModel = Lasso(alpha=lambdas[ii]).fit(xTrain, yTrain)\n",
    "    cont[ii,0] = lambdas[ii]\n",
    "    error = mean_squared_error(yTest,ridgeModel.predict(xTest),squared=False)\n",
    "    cont[ii,1] = error\n",
    "\n",
    "plt.plot(cont[:,0],cont[:,1])\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Lasso regression')\n",
    "plt.show()\n",
    "print('Optimal lambda:',lambdas[np.argmax(cont[:,1]==np.min(cont[:,1]))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Detour : Using Autograd (and more importantly computing gradients!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd is a package for automatic differentiation.  ``autograd.numpy`` is a wrapper for Numpy which contains the same basic operations.  In most machine learning algorithms we need the gradient of a certain loss function to fit our model to the given data.  Autograd computes this gradient automatically for us so that we may use methods such as gradient descent.  A popular function used in logistic regression as well as neural nets is the sigmoid function\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "The derivative is given by\n",
    "\n",
    "$$\n",
    "\\sigma'(x) = \\frac{e^{-x}}{(1 + e^{-x})^2} = \\sigma(x) (1 - \\sigma(x))\n",
    "$$\n",
    "\n",
    "We could either compute this derivative by hand and then hard code it explicitly, or we could just call autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Hard code the gradient of the sigmoid function.\n",
    "def grad_sigmoid(x):\n",
    "    y = sigmoid(x)\n",
    "    return y * (1 - y)\n",
    "\n",
    "# Evaluate the gradient using autograd.\n",
    "grad_sig = grad(sigmoid)\n",
    "\n",
    "# Plot the two gradients side by side.\n",
    "x = np.linspace(-4, 4, 100)\n",
    "\n",
    "\n",
    "# We'll have 2 plots side by side.\n",
    "fig = plt.figure(3, figsize = (10, 5))\n",
    "\n",
    "# First plot the autograd derivative.\n",
    "ax1 = plt.subplot(121) # create a figure with 1 row and 2 columns and get the axis \n",
    "y1 = np.asarray([grad_sig(x[i]) for i in range(len(x))])\n",
    "ax1.plot(x, y1, 'b')\n",
    "ax1.set_xlabel(r'$x$')\n",
    "ax1.set_ylabel(r'$\\sigma\\'(x)$')\n",
    "ax1.set_title(r'Autograd $\\sigma\\'(x)$')\n",
    "\n",
    "# Second plot the hard-coded derivative.\n",
    "ax2 = plt.subplot(122)\n",
    "y2 = grad_sigmoid(x)\n",
    "ax2.plot(x, y2, 'r')\n",
    "ax2.set_xlabel(r'$x$')\n",
    "ax2.set_ylabel(r'$\\sigma\\'(x)$')\n",
    "ax2.set_title(r'Hard coded $\\sigma\\'(x)$')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using Synthetic Data and Autograd\n",
    "\n",
    "We will play around with the logistic regression model implemented from scratch and trained using autograd on synthetic data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data and plot it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the plots in the remainder of this notebook we will use a widget to get interactive and better looking plots! \n",
    "# follow these instructions to set up matplotlib widget for Jupyter Lab\n",
    "# https://github.com/matplotlib/jupyter-matplotlib#installation\n",
    "# Specifically you will need to install the widget using : conda install -c conda-forge ipympl\n",
    "# To enable the widget run the following two commands :\n",
    "# jupyter nbextension install --py --symlink --sys-prefix --overwrite ipympl\n",
    "#jupyter nbextension enable --py --sys-prefix ipympl\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# random_seed = numpy.random.randint(0,100)\n",
    "random_seed = 65\n",
    "\n",
    "x, y = make_blobs(n_samples=2000, centers=2, n_features=2, random_state=random_seed)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(x[:,0], x[:,1], c=y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a set of data points $\\{(x_{1}, y_{1}), (x_{2}, y_{2}), ... , (x_{n}, y_{n})\\}$, where $x_{i} \\in R^{d}$ are the feature vectors and $y_{i} \\in \\{0, 1\\}$ are the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training set and validation set\n",
    "We consider the first 1500 points as our training set and the remaining 500 as our validation set. \n",
    "<b>Is this correct?</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:1500], y[:1500]\n",
    "x_val, y_val = x[1500:], y[1500:]\n",
    "\n",
    "# sanity check\n",
    "assert len(x_train) == len(y_train) == 1500\n",
    "assert len(x_val) == len(y_val) == 500\n",
    "\n",
    "# should we check anything else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "Logistic regression model outputs the posterior probability of the class label to be equal to 1. \n",
    "$$p_{+} = p(y = 1|x) = \\frac{1}{1 + e^{-w \\cdot x + b}},$$ \n",
    "where $w \\in R^{d}$ and $b \\in R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function is used to convert the output of the linear operation into probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function(f):\n",
    "    x = numpy.linspace(-10,10,100)\n",
    "    y = f(x)\n",
    "    \n",
    "    return plt.plot(x,y)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plot_function(sigmoid)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets build the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_unit(x, w, b):\n",
    "    \"\"\"This function computes logistic unit as defined $p_{+}$ above\n",
    "    :param x: input x with n_dim features\n",
    "    :param w: weght vector\n",
    "    :param b: bias vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # operator @ means matrix multiplication in python <3.5\n",
    "    # https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.matmul.html#numpy.matmul\n",
    "    \n",
    "    pre_sigmoid = x @ w + b\n",
    "    logit = sigmoid(pre_sigmoid)\n",
    "    \n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "The loss function of the logistic regression is given by: \n",
    "\n",
    "$$\\mathcal{L}(x,y) = - ( y \\cdot \\log(p_{+}) + (1 - y) \\cdot \\log(1 - p_{+}) )$$\n",
    "\n",
    "Note that $p_{+}$ depends on $x$ and $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAR_ZERO = 1e-12\n",
    "\n",
    "def loss_function(x, y, w, b):\n",
    "    \"\"\"This function computes the loss (distance)\n",
    "    :param logits: output from logistic unit\n",
    "    :param labels: target label\n",
    "    \"\"\"\n",
    "    logits = logistic_unit(x,w,b)\n",
    "    labels = y\n",
    "    \n",
    "    loss = -(labels * numpy.log(logits + NEAR_ZERO) + (1 - labels) * numpy.log(1 - logits + NEAR_ZERO))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do a sanity check and compute the loss between the target and prediction given a randomly initialized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "n_dim=2\n",
    "w0 = 0.01 * numpy.random.randn(n_dim)\n",
    "b0 = 0.0\n",
    "\n",
    "inp = x_train[0]\n",
    "label = y_train[0]\n",
    "\n",
    "out = logistic_unit(inp, w0, b0)\n",
    "assert (out < 1) and (out > 0)  # why?\n",
    "\n",
    "loss = loss_function(inp, label, w0, b0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above loss function is also called the binary cross-entropy loss. As the true label is either 0 or 1, we can rewrite the above equation as two separate equations. <br />\n",
    "When $y = 1$, the second term in the above equation goes to zero, and the equation reduces to $-\\log(p)$. Therefore, when $y = 1$, the binary cross-entropy loss is equal to the negative logarithm of the predicted probability $p$. Similarly, when the true label $y = 0$, the term $y log(p)$ vanishes, and the expression for binary cross-entropy loss reduces to: $-\\log(1-p)$. We can plot each of these components below and see how the loss values change for different values of the true label and the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.linspace(0.001,1)\n",
    "log_x = np.log(x_arr)\n",
    "fig, axes = plt.subplots(1, 2,figsize=(8,4))\n",
    "sns.lineplot(ax=axes[0],x=x_arr,y=log_x)\n",
    "axes[0].set_title('Plot of log(x) in the interval (0,1]')\n",
    "axes[0].set(xlabel='x', ylabel='log(x)')\n",
    "sns.lineplot(ax=axes[1],x=x_arr,y=-log_x)\n",
    "axes[1].set_title('Plot of -log(x) in the interval (0,1]')\n",
    "axes[1].set(xlabel='x', ylabel='-log(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting together the cross entropy loss can be visualized as,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "fig, axes = plt.subplots(1, 1,figsize=(8,4))\n",
    "\n",
    "p = np.linspace(0,1,20)\n",
    "bce_1 = -np.log(p)\n",
    "bce_0 = -np.log(1-p)\n",
    "plot1 = sns.lineplot(x=p,y=bce_1,label='True value:1').set(ylim=(0,4))\n",
    "plot2 = sns.lineplot(x=p,y=bce_0,label='True value:0').set(ylim=(0,4))\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Autograd for computing the derivatives and train the model\n",
    "As discussed in the previous lab, with Autograd we do not need to compute the gradients by hand and code it. This is very handy when we have huge DAG (Directed Acyclic Graph) computations.\n",
    "There is an active line of research in automatic differentiation, curious students are adviced to read this:\n",
    "http://jmlr.org/papers/volume18/17-468/17-468.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install autograd:\n",
    "#!conda install -c conda-forge autograd\n",
    "\n",
    "import autograd.numpy as numpy\n",
    "import autograd.numpy.random as npr\n",
    "\n",
    "from autograd import elementwise_grad\n",
    "\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grad_w = elementwise_grad(loss_function, 2) # partial derivative wrt the weights w (3rd input)\n",
    "loss_grad_b = elementwise_grad(loss_function, 3) # partial derivative wrt the bias b (4th input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10000\n",
    "eta = .0001   # Learning rate\n",
    "w = numpy.copy(w0)\n",
    "b = numpy.copy(b0)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for ni in tqdm(range(n_iter)):\n",
    "    dw = loss_grad_w(x_train, y_train, w, b)\n",
    "    db = loss_grad_b(x_train, y_train, w, b)\n",
    "    w -= eta * dw\n",
    "    b -= eta * db\n",
    "    \n",
    "    loss = numpy.mean(loss_function(x_train, y_train, w, b))\n",
    "    loss_log.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the running element-wise loss value\n",
    "plt.figure()\n",
    "plt.plot(loss_log)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data: the actual data and the model (hyperplane)\n",
    "We start with first defining some visualization routines and then we do the actual plotting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some visualization routines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data \n",
    "def vis_data(x, y = None, c='r'):\n",
    "    if y is None: \n",
    "        y = [None] * len(x)\n",
    "    for x_, y_ in zip(x, y):\n",
    "        if y_ is None:\n",
    "            plt.plot(x_[0], x_[1], 'o', markerfacecolor='none', markeredgecolor=c)\n",
    "        else:\n",
    "            plt.plot(x_[0], x_[1], 'b'+'o' if y_ == 0 else 'y'+'+')\n",
    "    plt.grid('on')\n",
    "    \n",
    "def vis_hyperplane(w, b, typ='k--'):\n",
    "\n",
    "    lim0 = plt.gca().get_xlim()\n",
    "    lim1 = plt.gca().get_ylim()\n",
    "    m0, m1 = lim0[0], lim0[1]\n",
    "\n",
    "    intercept0 = -(w[0] * m0 + b)/w[1]\n",
    "    intercept1 = -(w[0] * m1 + b)/w[1]\n",
    "    \n",
    "    plt1, = plt.plot([m0, m1], [intercept0, intercept1], typ)\n",
    "\n",
    "    plt.gca().set_xlim(lim0)\n",
    "    plt.gca().set_ylim(lim1)\n",
    "        \n",
    "    return plt1\n",
    "\n",
    "def vis_decision_boundary_contour(w, b, typ='k--'):\n",
    "    \n",
    "    lim0 = plt.gca().get_xlim()\n",
    "    lim1 = plt.gca().get_ylim()\n",
    "    \n",
    "    x_ = numpy.linspace(lim0[0], lim0[1], 100)\n",
    "    y_ = numpy.linspace(lim1[0], lim1[1], 100)\n",
    "    xx, yy = numpy.meshgrid(x_, y_)\n",
    "    \n",
    "    x_tra_ = numpy.concatenate([xx.ravel()[:,None], yy.ravel()[:,None]], axis=1)\n",
    "    \n",
    "    pred = logistic_unit(x_tra_, w, b)\n",
    "    plt1 = plt.contourf(xx, yy, pred.reshape(xx.shape), cmap=plot.cm.coolwarm, alpha=0.4)\n",
    "    \n",
    "    plt.colorbar(plt1)\n",
    "    \n",
    "    plt.gca().set_xlim(lim0)\n",
    "    plt.gca().set_ylim(lim1)\n",
    "        \n",
    "    return plt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "vis_data(x, y, c='b')\n",
    "\n",
    "plt0 = vis_hyperplane(w0, b0, 'k-.')\n",
    "plt1 = vis_hyperplane(w, b, 'k--')\n",
    "plt.legend([plt0, plt1], [\n",
    "        'Initial: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w0)+[b0]),\n",
    "        'Final: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w)+[b])],\n",
    "           loc='best')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression for Breast Cancer Classification using Sklearn\n",
    "\n",
    "We will now implement and train another logistic regression model using Sci-kit learn. The goal will be to implement the model, which given a new data point infers the probability of breast cancer. \n",
    "\n",
    "Helper method below copied from: [Helper Method](https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General helper method to convert sci-kit datasets to Pandas DataFrame.\n",
    "def sklearn_to_df(sklearn_dataset):\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Series(sklearn_dataset.target)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's eyeball the data a little bit in a quick and hacky manner. Always a good practice to see what the data looks like. **The training data of course!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset = datasets.load_breast_cancer() # Load the data and convert to a pandas dataframe\n",
    "df = sklearn_to_df(cancer_dataset)\n",
    "\n",
    "print(df.head()) # Print out the first five data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's gather a few summary statistics about our data. Again, always a good practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df) # The number of data points.\n",
    "print('N = {:d} data points'.format(N))\n",
    "\n",
    "# Give a barplot of each class.\n",
    "plt.figure()\n",
    "plt.bar([0,1], df['target'].value_counts(ascending = True), color = ['r', 'b'], tick_label = cancer_dataset.target_names)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Cancer Dataset: Class Counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is unbalanced because there are more examples of benign cancer than malignant.  This is typical of many real-life datasets where we are sometimes limited in how many training examples we have.  Let's split our data into a training and validation set.  We'll use a 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data.  DO NOT TOUCH THE TEST DATA FROM HERE ON!!\n",
    "train_data, val_data = model_selection.train_test_split(df, test_size = 0.2) # 0.2 is 20% validation data.\n",
    "\n",
    "# Split the features from the class labels.\n",
    "X_train = train_data.drop('target', axis = 1) # We drop the target from the features.  \n",
    "X_val  = val_data.drop('target', axis = 1)  # Note that this does not operate inplace.\n",
    " \n",
    "y_train = train_data['target']\n",
    "y_val  = val_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is loaded and split we can train a logistic regression model.  For the optimization we use the \"liblinear\" solver.  There are many other solvers that are also available, such as Newton CG for example.  For more information there is a nice stackexchange post here: [Solvers](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit a logistic regression model.\n",
    "model = LogisticRegression(solver = 'liblinear')\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained so we can validate it on our validation set.  The Sci-kit metrics module contains many useful functions for this purpose.  We try out a few of them below. \n",
    "\n",
    "Let us first briefly explain some of these metrics we will use.  \n",
    "\n",
    "#### Accuracy \n",
    "Accuracy is obviously the percentage of all correctly classified examples in our test set.  \n",
    "\n",
    "#### Confusion Matrix\n",
    "The confusion matrix is the following matrix:\n",
    "$$\n",
    "C = \\begin{bmatrix}\n",
    "\\text{Predict 0, Actual 0} & \\text{Predict 0, Actual 1}\\\\\n",
    "\\text{Predict 1, Actual 0} & \\text{Predict 1, Actual 1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Notice that the diagonal entries are the examples that are correctly classified.  \n",
    "\n",
    "#### Precision Score\n",
    "The precision score is the percentage \n",
    "$$\n",
    "\\text{Precision } = \\frac{C_{00}}{C_{00} + C_{01}}.\n",
    "$$\n",
    "So it is the percentage of predicted malignant tumors that we classify correctly.  \n",
    "\n",
    "#### Recall Score \n",
    "The recall score is the percentage\n",
    "$$\n",
    "\\text{Recall } = \\frac{C_{00}}{C_{00} + C_{10}}\n",
    "$$\n",
    "So it is the percentage of malignant tumors that we classify correctly. Note that Precision and Recall are two different quantities.\n",
    "\n",
    "**Using multiple evaluation metrics helps give a better picture of how well our classifier is doing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)\n",
    "\n",
    "# See the percentage of examples that are correctly classified.\n",
    "accuracy = metrics.accuracy_score(y_val, pred) \n",
    "print(\"Accuracy = {:0.1f}%\".format(accuracy * 100))\n",
    "\n",
    "# The matrix of predictions and true values for each class.\n",
    "conf_matrix = metrics.confusion_matrix(y_val, pred)\n",
    "print(\"Confusion matrix = \")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision score.\n",
    "precision = metrics.precision_score(y_val, pred)\n",
    "print(\"Precision = {:0.1f}%\".format(100 * precision))\n",
    "\n",
    "# Recall score.\n",
    "recall = metrics.recall_score(y_val, pred)\n",
    "print(\"Recall    = {:0.1f}%\".format(100 * recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also plot the ROC curve and use it to estimate thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict_proba(X_val)\n",
    "metrics.RocCurveDisplay.from_predictions(y_val, pred_probs[:,1])\n",
    "\n",
    "# or alternatively\n",
    "metrics.RocCurveDisplay.from_estimator(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we have highly imbalanced classes, we can plot the PR curve as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.PrecisionRecallDisplay.from_predictions(y_val, pred_probs[:,1])\n",
    "\n",
    "# or alternatively\n",
    "metrics.PrecisionRecallDisplay.from_estimator(model, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
